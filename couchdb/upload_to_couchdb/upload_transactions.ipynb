{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_17220\\4094813108.py:47: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  groups_data = pd.read_csv(groups_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added batch of 50000 transactions to CouchDB.\n",
      "Successfully added remaining 25242 transactions to CouchDB.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import math\n",
    "\n",
    "username = \"admin\"  # Replace with your CouchDB username\n",
    "password = \"admin\"  # Replace with your CouchDB password\n",
    "couchdb_url = \"http://127.0.0.1:5984/\"\n",
    "\n",
    "def handle_nan(value, default='Unknown'):\n",
    "    if pd.isna(value) or value is None or (isinstance(value, float) and math.isnan(value)):\n",
    "        return default\n",
    "    return value\n",
    "\n",
    "def upload_transaction_to_couchdb(transactions, batch_size=50000):\n",
    "    # Prepare the payload for bulk upload\n",
    "    payload = {\"docs\": []}\n",
    "\n",
    "    for transaction in transactions:\n",
    "        payload[\"docs\"].append(transaction)\n",
    "\n",
    "        # If we reach the batch size, send the current batch\n",
    "        if len(payload[\"docs\"]) == batch_size:\n",
    "            response = requests.post(couchdb_url + \"transactions/_bulk_docs\", json=payload, auth=(username, password))\n",
    "            if response.status_code == 201:\n",
    "                print(f\"Successfully added batch of {batch_size} transactions to CouchDB.\")\n",
    "            else:\n",
    "                print(f\"Failed to add batch to CouchDB: {response.text}\")\n",
    "            \n",
    "            # Reset the payload for the next batch\n",
    "            payload[\"docs\"] = []\n",
    "\n",
    "    # Check for any remaining transactions that didn't fill a complete batch\n",
    "    if payload[\"docs\"]:\n",
    "        response = requests.post(couchdb_url + \"transactions/_bulk_docs\", json=payload, auth=(username, password))\n",
    "        if response.status_code == 201:\n",
    "            print(f\"Successfully added remaining {len(payload['docs'])} transactions to CouchDB.\")\n",
    "        else:\n",
    "            print(f\"Failed to add remaining transactions to CouchDB: {response.text}\")\n",
    "\n",
    "# Function to upload transactions with embedded album details\n",
    "def upload_transactions_with_albums(transaction_file, transaction_album_file, albums_file, groups_file):\n",
    "    transactions_data = pd.read_csv(transaction_file)\n",
    "    transaction_albums_data = pd.read_csv(transaction_album_file)\n",
    "    albums_data = pd.read_csv(albums_file)\n",
    "    groups_data = pd.read_csv(groups_file)\n",
    "\n",
    "    albums_dict = albums_data.set_index('id').to_dict(orient='index')\n",
    "    groups_dict = groups_data.set_index('id').to_dict(orient='index')\n",
    "    transaction_albums_grouped = transaction_albums_data.groupby('transaction_id')\n",
    "\n",
    "    transactions_json = []\n",
    "\n",
    "    for _, transaction in transactions_data.iterrows():\n",
    "        transaction_id = int(transaction['id'])\n",
    "\n",
    "        # Get albums for this transaction\n",
    "        related_albums = []\n",
    "        if transaction_id in transaction_albums_grouped.groups:\n",
    "            album_ids = transaction_albums_grouped.get_group(transaction_id)['album_id']\n",
    "            for album_id in album_ids:\n",
    "                album_info = albums_dict.get(int(album_id), {}).copy()  # Copy to avoid modifying original dict\n",
    "                album_info['id'] = album_id\n",
    "\n",
    "                # Get group info based on group_id from album data\n",
    "                group_id = album_info.get('group_id')\n",
    "                if group_id and group_id in groups_dict:\n",
    "                    album_info['group_name'] = groups_dict[group_id]['name']\n",
    "                else:\n",
    "                    album_info['group_name'] = None  # Fallback if group is not found\n",
    "\n",
    "                album_entry = {\n",
    "                    '_id': str(album_id),\n",
    "                    'name': handle_nan(album_info['title']),\n",
    "                    'group': handle_nan(album_info['group_name']),\n",
    "                    'quantity': handle_nan(album_info['stock']),\n",
    "                    'price': handle_nan(album_info['price'])\n",
    "                }\n",
    "\n",
    "                related_albums.append(album_entry)\n",
    "\n",
    "        transaction_data = transaction.to_dict()\n",
    "        transaction_data['albums'] = related_albums\n",
    "\n",
    "        transaction_entry = {\n",
    "            '_id': str(transaction_data['id']),\n",
    "            'customer_id': handle_nan(transaction_data['customer_id']),\n",
    "            'transaction_date': handle_nan(transaction_data['transaction_date']),\n",
    "            'status': handle_nan(transaction_data['status']),\n",
    "            'albums': transaction_data['albums']\n",
    "        }\n",
    "\n",
    "        transactions_json.append(transaction_entry)\n",
    "\n",
    "    upload_transaction_to_couchdb(transactions_json)\n",
    "\n",
    "    # # Upload transactions to CouchDB\n",
    "    # with ThreadPoolExecutor(max_workers=15) as executor:  # Adjust max_workers as needed\n",
    "    #     executor.map(upload_transaction_to_couchdb, transactions_json)\n",
    "\n",
    "# Upload Transactions with embedded album details\n",
    "upload_transactions_with_albums(\"transactions.csv\", \"transaction_albums.csv\", \"albums.csv\", \"groups.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
