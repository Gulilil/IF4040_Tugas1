{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_18484\\4012273430.py:50: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  groups_data = pd.read_csv(group_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added batch of 50000 groups to CouchDB.\n",
      "Successfully added batch of 50000 groups to CouchDB.\n",
      "Successfully added batch of 50000 groups to CouchDB.\n",
      "Successfully added batch of 50000 groups to CouchDB.\n",
      "Successfully added batch of 50000 groups to CouchDB.\n",
      "Successfully added batch of 50000 groups to CouchDB.\n",
      "Successfully added batch of 50000 groups to CouchDB.\n",
      "Successfully added batch of 50000 groups to CouchDB.\n",
      "Successfully added remaining 41053 groups to CouchDB.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import math\n",
    "\n",
    "username = \"admin\"  # Replace with your CouchDB username\n",
    "password = \"admin\"  # Replace with your CouchDB password\n",
    "couchdb_url = \"http://127.0.0.1:5984/\"\n",
    "\n",
    "def handle_nan(value, default='Unknown'):\n",
    "    if pd.isna(value) or value is None or (isinstance(value, float) and math.isnan(value)):\n",
    "        return default\n",
    "    return value\n",
    "\n",
    "def upload_group_to_couchdb(groups, batch_size=50000):\n",
    "    # Prepare the payload for bulk upload\n",
    "    payload = {\"docs\": []}\n",
    "\n",
    "    for group in groups:\n",
    "        payload[\"docs\"].append(group)\n",
    "        \n",
    "        # print(\"group:\")\n",
    "        # print(\"      \", group)\n",
    "\n",
    "        # print(\"groups:\")\n",
    "        # print(\"      \", groups)\n",
    "\n",
    "        # If we reach the batch size, send the current batch\n",
    "        if len(payload[\"docs\"]) == batch_size:\n",
    "            response = requests.post(couchdb_url + \"groups/_bulk_docs\", json=payload, auth=(username, password))\n",
    "            if response.status_code == 201:\n",
    "                print(f\"Successfully added batch of {batch_size} groups to CouchDB.\")\n",
    "            else:\n",
    "                print(f\"Failed to add batch to CouchDB: {response.text}\")\n",
    "            \n",
    "            # Reset the payload for the next batch\n",
    "            payload[\"docs\"] = []\n",
    "\n",
    "    # Check for any remaining groups that didn't fill a complete batch\n",
    "    if payload[\"docs\"]:\n",
    "        response = requests.post(couchdb_url + \"groups/_bulk_docs\", json=payload, auth=(username, password))\n",
    "        if response.status_code == 201:\n",
    "            print(f\"Successfully added remaining {len(payload['docs'])} groups to CouchDB.\")\n",
    "        else:\n",
    "            print(f\"Failed to add remaining groups to CouchDB: {response.text}\")\n",
    "\n",
    "# Function to upload groups with embedded company details\n",
    "def upload_groups(group_file, company_file):\n",
    "    groups_data = pd.read_csv(group_file)\n",
    "    companies_data = pd.read_csv(company_file)\n",
    "\n",
    "    companies_dict = companies_data.set_index('id').to_dict(orient='index')\n",
    "\n",
    "    groups_json = []  # List to hold the JSON data\n",
    "\n",
    "    for _, group in groups_data.iterrows():\n",
    "        group_id = int(group['id'])\n",
    "\n",
    "        group_data = group.to_dict()\n",
    "\n",
    "        if pd.notna(group['company_id']):\n",
    "            group_data['company'] = {\n",
    "                '_id': str(int(group['company_id']))\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            group_data['company'] = {}\n",
    "\n",
    "        group_data.pop('company_id', None)\n",
    "\n",
    "        if 'debut' in group_data:\n",
    "            group_data['debut_date'] = group_data.pop('debut')\n",
    "\n",
    "        group_entry = {\n",
    "            '_id': str(group_data['id']),\n",
    "            'name': handle_nan(group_data['name']),\n",
    "            'debut_date': handle_nan(group_data['debut_date']),\n",
    "            'company': handle_nan(group_data['company']),\n",
    "            'fanclub_name': handle_nan(group_data['fanclub_name']),\n",
    "            'active': handle_nan(group_data['active']),\n",
    "            'type': handle_nan(group_data['type'])\n",
    "        }\n",
    "        \n",
    "        groups_json.append(group_entry)\n",
    "            \n",
    "    upload_group_to_couchdb(groups_json)\n",
    "    # # Use ThreadPoolExecutor to parallelize the uploads\n",
    "    # with ThreadPoolExecutor(max_workers=15) as executor:  # Adjust max_workers as needed\n",
    "    #     executor.map(upload_group_to_couchdb, groups_json)\n",
    "\n",
    "# Upload Groups with embedded company details\n",
    "upload_groups(\"groups.csv\", \"companies.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
