{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o-PHXf6zaJTT"
      },
      "outputs": [],
      "source": [
        "# # Step 1: Install Firebase Admin SDK\n",
        "# !pip install firebase-admin\n",
        "\n",
        "# # Step 2: Import required libraries\n",
        "# import firebase_admin\n",
        "# from firebase_admin import credentials, firestore\n",
        "# from google.colab import files\n",
        "\n",
        "# # Step 3: Upload the service account key JSON file (you need to upload this)\n",
        "# print(\"Please upload your Firebase service account key file (JSON)\")\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# # Step 4: Initialize Firestore with the uploaded credentials\n",
        "# cred = credentials.Certificate(list(uploaded.keys())[0])  # Use the uploaded file\n",
        "# firebase_admin.initialize_app(cred)\n",
        "\n",
        "# # Connect to Firestore\n",
        "# db = firestore.client()\n",
        "\n",
        "# # Step 5: Add two album documents to the 'Albums' collection\n",
        "\n",
        "# # Album 1\n",
        "# album_1 = {\n",
        "#     'ID': 'album_001',\n",
        "#     'Name': 'The Dark Side of the Moon',\n",
        "#     'Year': 1973,\n",
        "#     'Artist': 'Pink Floyd'\n",
        "# }\n",
        "\n",
        "# # Album 2\n",
        "# album_2 = {\n",
        "#     'ID': 'album_002',\n",
        "#     'Name': 'Abbey Road',\n",
        "#     'Year': 1969,\n",
        "#     'Artist': 'The Beatles'\n",
        "# }\n",
        "\n",
        "# # Insert Album 1\n",
        "# db.collection('Albums').document(album_1['ID']).set(album_1)\n",
        "# print(f\"Album {album_1['Name']} uploaded successfully!\")\n",
        "\n",
        "# # Insert Album 2\n",
        "# db.collection('Albums').document(album_2['ID']).set(album_2)\n",
        "# print(f\"Album {album_2['Name']} uploaded successfully!\")\n",
        "\n",
        "# # Step 6: Create a transactionAlbums document with an array of album IDs\n",
        "\n",
        "# transaction_album = {\n",
        "#     'ID': 'txn_001',\n",
        "#     'albumIds': [album_1['ID'], album_2['ID']]  # Array of Album IDs\n",
        "# }\n",
        "\n",
        "# # Insert transactionAlbums\n",
        "# db.collection('transactionAlbums').document(transaction_album['ID']).set(transaction_album)\n",
        "# print(\"transactionAlbums document uploaded successfully with album IDs!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwqffNiExW-c"
      },
      "source": [
        "# Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "d2_kapxSFNVs",
        "outputId": "2f7793a3-9e49-4a63-855f-00c9f85ed24d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HXSSLqv18jo0oX3K8mO2d_YkAmKXazLc\n",
            "To: c:\\Users\\louis\\Downloads\\albums.csv\n",
            "100%|██████████| 36.8M/36.8M [00:30<00:00, 1.19MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1V1ZPXXVNEAQRvM7Yd4cywJ_KZ1YhFX5Y\n",
            "To: c:\\Users\\louis\\Downloads\\companies.csv\n",
            "100%|██████████| 20.0M/20.0M [00:21<00:00, 941kB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1FmbGOPTaLqGKulYKXWCTxdtTV5ePAXUS\n",
            "To: c:\\Users\\louis\\Downloads\\countries.csv\n",
            "100%|██████████| 8.24k/8.24k [00:00<00:00, 1.10MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1VkKQlZVmndjLQ2Tthwa_-p8Bk_1rRnFV\n",
            "To: c:\\Users\\louis\\Downloads\\customers.csv\n",
            "100%|██████████| 58.2M/58.2M [00:49<00:00, 1.17MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WMHXjv0stPToDGi57kpEnkms5SIMnnB2\n",
            "To: c:\\Users\\louis\\Downloads\\groups.csv\n",
            "100%|██████████| 31.1M/31.1M [00:20<00:00, 1.53MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HA1YL_RinEjXOdbibh1UrjXW2II0t3Zc\n",
            "To: c:\\Users\\louis\\Downloads\\idols.csv\n",
            "100%|██████████| 38.1M/38.1M [00:18<00:00, 2.03MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19hflEUzu-J1zSU_W0blu30yfJ2_sdZXi\n",
            "To: c:\\Users\\louis\\Downloads\\songs.csv\n",
            "100%|██████████| 22.1M/22.1M [00:11<00:00, 1.86MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JhLwJs-pseSrolo92dpCW6Z4kLKSQUCr\n",
            "To: c:\\Users\\louis\\Downloads\\transaction_albums.csv\n",
            "100%|██████████| 86.6M/86.6M [00:39<00:00, 2.19MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=111ZsIh8y-XnRbYAGpYBU_taqwGhOhNcx\n",
            "To: c:\\Users\\louis\\Downloads\\transactions.csv\n",
            "100%|██████████| 82.2M/82.2M [00:37<00:00, 2.20MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'transactions.csv'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get all csvs\n",
        "import gdown\n",
        "\n",
        "# Use the file ID\n",
        "albums_id = '1HXSSLqv18jo0oX3K8mO2d_YkAmKXazLc'\n",
        "companies_id = '1V1ZPXXVNEAQRvM7Yd4cywJ_KZ1YhFX5Y'\n",
        "countries_id = '1FmbGOPTaLqGKulYKXWCTxdtTV5ePAXUS'\n",
        "customers_id = '1VkKQlZVmndjLQ2Tthwa_-p8Bk_1rRnFV'\n",
        "groups_id = '1WMHXjv0stPToDGi57kpEnkms5SIMnnB2'\n",
        "idols_id = '1HA1YL_RinEjXOdbibh1UrjXW2II0t3Zc'\n",
        "songs_id = '19hflEUzu-J1zSU_W0blu30yfJ2_sdZXi'\n",
        "transaction_albums_id = '1JhLwJs-pseSrolo92dpCW6Z4kLKSQUCr'\n",
        "transactions_id = '111ZsIh8y-XnRbYAGpYBU_taqwGhOhNcx'\n",
        "\n",
        "gdown.download(f'https://drive.google.com/uc?id={albums_id}', 'albums.csv', quiet=False)\n",
        "gdown.download(f'https://drive.google.com/uc?id={companies_id}', 'companies.csv', quiet=False)\n",
        "gdown.download(f'https://drive.google.com/uc?id={countries_id}', 'countries.csv', quiet=False)\n",
        "gdown.download(f'https://drive.google.com/uc?id={customers_id}', 'customers.csv', quiet=False)\n",
        "gdown.download(f'https://drive.google.com/uc?id={groups_id}', 'groups.csv', quiet=False)\n",
        "gdown.download(f'https://drive.google.com/uc?id={idols_id}', 'idols.csv', quiet=False)\n",
        "gdown.download(f'https://drive.google.com/uc?id={songs_id}', 'songs.csv', quiet=False)\n",
        "gdown.download(f'https://drive.google.com/uc?id={transaction_albums_id}', 'transaction_albums.csv', quiet=False)\n",
        "gdown.download(f'https://drive.google.com/uc?id={transactions_id}', 'transactions.csv', quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBEvfJbHxbym"
      },
      "source": [
        "# Countries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "hKg8BeZmxbmC",
        "outputId": "6288af59-1fdc-4712-a6be-a4ef940ce845"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import requests\n",
        "\n",
        "username = \"admin\"  # Replace with your CouchDB username\n",
        "password = \"admin\"  # Replace with your CouchDB password\n",
        "\n",
        "# Function to upload countries\n",
        "def upload_countries(country_file, couchdb_url):\n",
        "    countries_data = pd.read_csv(country_file)\n",
        "    countries_json = []  # List to hold the JSON data\n",
        "\n",
        "\n",
        "    for _, country in countries_data.iterrows():\n",
        "        country_id = str(country['id'])\n",
        "        country_data = country.to_dict()\n",
        "\n",
        "        country_entry = {\n",
        "            '_id': str(country_data['id']),\n",
        "            'name': country_data['name'],\n",
        "            'capital': country_data['capital'],\n",
        "            'currency': country_data['currency'],\n",
        "            'continent': country_data['continent'],\n",
        "        }\n",
        "\n",
        "        # print(json.dumps(country_entry, indent=4))\n",
        "\n",
        "        # db.collection('countries').document(country_id).set(country_entry)\n",
        "        # print(f\"Uploaded country {country_id}.\")\n",
        "\n",
        "        countries_json.append(country_entry)\n",
        "\n",
        "    # Send POST requests to CouchDB\n",
        "    for country in countries_json:\n",
        "        print(json.dumps(country, indent=4))\n",
        "        response = requests.post(couchdb_url + \"countries\", json=country, auth=(username, password))\n",
        "        if response.status_code == 201:\n",
        "            print(f\"Successfully added country to CouchDB: {country['name']}\")\n",
        "        else:\n",
        "            print(f\"Failed to add {country['name']} to CouchDB: {response.text}\")\n",
        "\n",
        "# Upload Countries\n",
        "couchdb_url = \"http://127.0.0.1:5984/\"\n",
        "upload_countries(\"countries.csv\", couchdb_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyQl66-axkLt"
      },
      "source": [
        "# Companies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "bTqIcNalxklH",
        "outputId": "6dce0587-ef86-41f5-b621-8cf72795d72a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully added batch of 50000 companies to CouchDB.\n",
            "Successfully added batch of 50000 companies to CouchDB.\n",
            "Successfully added batch of 50000 companies to CouchDB.\n",
            "Successfully added batch of 50000 companies to CouchDB.\n",
            "Successfully added batch of 50000 companies to CouchDB.\n",
            "Successfully added batch of 50000 companies to CouchDB.\n",
            "Successfully added batch of 50000 companies to CouchDB.\n",
            "Successfully added batch of 50000 companies to CouchDB.\n",
            "Successfully added remaining 46756 companies to CouchDB.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import math\n",
        "\n",
        "username = \"admin\"  # Replace with your CouchDB username\n",
        "password = \"admin\"  # Replace with your CouchDB password\n",
        "couchdb_url = \"http://127.0.0.1:5984/\"\n",
        "\n",
        "def handle_nan(value, default='Unknown'):\n",
        "    if pd.isna(value) or value is None or (isinstance(value, float) and math.isnan(value)):\n",
        "        return default\n",
        "    return value\n",
        "\n",
        "def upload_company_to_couchdb(companies, batch_size=50000):\n",
        "    # Prepare the payload for bulk upload\n",
        "    payload = {\"docs\": []}\n",
        "\n",
        "    for company in companies:\n",
        "        payload[\"docs\"].append(company)\n",
        "\n",
        "        # If we reach the batch size, send the current batch\n",
        "        if len(payload[\"docs\"]) == batch_size:\n",
        "            response = requests.post(couchdb_url + \"companies/_bulk_docs\", json=payload, auth=(username, password))\n",
        "            if response.status_code == 201:\n",
        "                print(f\"Successfully added batch of {batch_size} companies to CouchDB.\")\n",
        "            else:\n",
        "                print(f\"Failed to add batch to CouchDB: {response.text}\")\n",
        "            \n",
        "            # Reset the payload for the next batch\n",
        "            payload[\"docs\"] = []\n",
        "\n",
        "    # Check for any remaining companies that didn't fill a complete batch\n",
        "    if payload[\"docs\"]:\n",
        "        response = requests.post(couchdb_url + \"companies/_bulk_docs\", json=payload, auth=(username, password))\n",
        "        if response.status_code == 201:\n",
        "            print(f\"Successfully added remaining {len(payload['docs'])} companies to CouchDB.\")\n",
        "        else:\n",
        "            print(f\"Failed to add remaining companies to CouchDB: {response.text}\")\n",
        "\n",
        "# Function to upload companies with embedded country details\n",
        "def upload_companies(company_file, country_file, couchdb_url):\n",
        "    companies_data = pd.read_csv(company_file)\n",
        "    countries_data = pd.read_csv(country_file)\n",
        "\n",
        "    # Convert countries CSV data into a dictionary for quick lookup by id\n",
        "    countries_dict = countries_data.set_index('id').to_dict(orient='index')\n",
        "\n",
        "    companies_json = []  # List to hold the JSON data\n",
        "\n",
        "    for _, company in companies_data.iterrows():\n",
        "        company_id = int(company['id'])\n",
        "\n",
        "        if company_id > 54369:\n",
        "            country_id = int(company['country_id'])\n",
        "\n",
        "            # Create a dictionary for the company data\n",
        "            company_data = {\n",
        "                '_id': str(company_id),\n",
        "                'name': company.get('name'),\n",
        "                'headquarters': company.get('headquarter'),\n",
        "                'founded_year': company.get('founded_year')\n",
        "            }\n",
        "\n",
        "            # Embed the country details in the company data\n",
        "            country_info = countries_dict.get(int(country_id))\n",
        "            if country_info:\n",
        "                company_data['country'] = {\n",
        "                    '_id': str(country_id),\n",
        "                    'name': country_info.get('name')\n",
        "                }\n",
        "            else:\n",
        "                company_data['country'] = {}  # Fallback in case the country is not found\n",
        "            \n",
        "            companies_json.append(company_data)\n",
        "\n",
        "    upload_company_to_couchdb(companies_json)\n",
        "\n",
        "    # # Use ThreadPoolExecutor to parallelize the uploads\n",
        "    # with ThreadPoolExecutor(max_workers=15) as executor:  # Adjust max_workers as needed\n",
        "    #     executor.map(upload_company_to_couchdb, companies_json)\n",
        "\n",
        "# Upload Companies with embedded country details\n",
        "upload_companies(\"companies.csv\", \"countries.csv\", couchdb_url)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
