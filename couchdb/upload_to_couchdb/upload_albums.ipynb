{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_16512\\1513724435.py:45: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  groups_data = pd.read_csv(group_file)\n",
      "C:\\Users\\louis\\AppData\\Local\\Temp\\ipykernel_16512\\1513724435.py:46: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  songs_data = pd.read_csv(song_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added batch of 50000 albums to CouchDB.\n",
      "Successfully added batch of 50000 albums to CouchDB.\n",
      "Successfully added batch of 50000 albums to CouchDB.\n",
      "Successfully added batch of 50000 albums to CouchDB.\n",
      "Successfully added batch of 50000 albums to CouchDB.\n",
      "Successfully added batch of 50000 albums to CouchDB.\n",
      "Successfully added batch of 50000 albums to CouchDB.\n",
      "Successfully added batch of 50000 albums to CouchDB.\n",
      "Successfully added batch of 50000 albums to CouchDB.\n",
      "Successfully added remaining 11364 albums to CouchDB.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import math\n",
    "\n",
    "username = \"admin\"  # Replace with your CouchDB username\n",
    "password = \"admin\"  # Replace with your CouchDB password\n",
    "couchdb_url = \"http://127.0.0.1:5984/\"\n",
    "\n",
    "def handle_nan(value, default='Unknown'):\n",
    "    if pd.isna(value) or value is None or (isinstance(value, float) and math.isnan(value)):\n",
    "        return default\n",
    "    return value\n",
    "\n",
    "def upload_album_to_couchdb(albums, batch_size=50000):\n",
    "    # Prepare the payload for bulk upload\n",
    "    payload = {\"docs\": []}\n",
    "\n",
    "    for album in albums:\n",
    "        payload[\"docs\"].append(album)\n",
    "\n",
    "        # If we reach the batch size, send the current batch\n",
    "        if len(payload[\"docs\"]) == batch_size:\n",
    "            response = requests.post(couchdb_url + \"albums/_bulk_docs\", json=payload, auth=(username, password))\n",
    "            if response.status_code == 201:\n",
    "                print(f\"Successfully added batch of {batch_size} albums to CouchDB.\")\n",
    "            else:\n",
    "                print(f\"Failed to add batch to CouchDB: {response.text}\")\n",
    "            \n",
    "            # Reset the payload for the next batch\n",
    "            payload[\"docs\"] = []\n",
    "\n",
    "    # Check for any remaining albums that didn't fill a complete batch\n",
    "    if payload[\"docs\"]:\n",
    "        response = requests.post(couchdb_url + \"albums/_bulk_docs\", json=payload, auth=(username, password))\n",
    "        if response.status_code == 201:\n",
    "            print(f\"Successfully added remaining {len(payload['docs'])} albums to CouchDB.\")\n",
    "        else:\n",
    "            print(f\"Failed to add remaining albums to CouchDB: {response.text}\")\n",
    "\n",
    "# Function to upload albums with embedded group and songs\n",
    "def upload_albums_with_groups_and_songs(album_file, group_file, song_file):\n",
    "    albums_data = pd.read_csv(album_file)\n",
    "    groups_data = pd.read_csv(group_file)\n",
    "    songs_data = pd.read_csv(song_file)\n",
    "\n",
    "    groups_dict = groups_data.set_index('id').to_dict(orient='index')\n",
    "    songs_grouped = songs_data.groupby('album_id')\n",
    "\n",
    "    albums_json = []  # List to hold the JSON data\n",
    "    \n",
    "    for _, album in albums_data.iterrows():\n",
    "        album_id = int(album['id'])\n",
    "\n",
    "        group_id = int(album['group_id'])\n",
    "\n",
    "        album_data = album.to_dict()\n",
    "        group_info = groups_dict.get(group_id)\n",
    "\n",
    "        # print(\"group\", group_info)\n",
    "\n",
    "        if (group_info):\n",
    "            album_data['group'] = {\n",
    "                '_id': str(group_id),\n",
    "                'name': handle_nan(group_info['name'])\n",
    "            }\n",
    "        else:\n",
    "            album_data['group'] = {}\n",
    "\n",
    "        # Embed songs in the album\n",
    "        if album_id in songs_grouped.groups:\n",
    "            album_songs = songs_grouped.get_group(album_id).to_dict(orient='records')\n",
    "            album_data['songs'] = album_songs\n",
    "\n",
    "            for song in album_data['songs']:\n",
    "                song.pop('album_id', None)\n",
    "        else:\n",
    "            album_data['songs'] = []\n",
    "\n",
    "        album_data.pop('group_id', None)\n",
    "\n",
    "        album_entry = {\n",
    "            '_id': str(album_data['id']),\n",
    "            'name': handle_nan(album_data['title']),\n",
    "            'release_date': handle_nan(album_data['release_date']),\n",
    "            'genre': handle_nan(album_data['genre']),\n",
    "            'stock': handle_nan(album_data['stock']),\n",
    "            'price': handle_nan(album_data['price']),\n",
    "            'group': album_data['group'],\n",
    "            'songs': album_data['songs']\n",
    "        }\n",
    "\n",
    "        albums_json.append(album_entry)\n",
    "        \n",
    "    upload_album_to_couchdb(albums_json)\n",
    "\n",
    "    # # Use ThreadPoolExecutor to parallelize the uploads\n",
    "    # with ThreadPoolExecutor(max_workers=15) as executor:  # Adjust max_workers as needed\n",
    "    #     executor.map(upload_album_to_couchdb, albums_json)\n",
    "\n",
    "# Upload Albums with embedded groups and songs\n",
    "upload_albums_with_groups_and_songs(\"albums.csv\", \"groups.csv\", \"songs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
